import os
import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.parallel import DataParallel
from torchvision import transforms
from PIL import Image
import albumentations as A
from albumentations.pytorch import ToTensorV2
from transformers import SegformerForSemanticSegmentation, SegformerConfig
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tqdm import tqdm
import json
from pathlib import Path
import time
import warnings
warnings.filterwarnings('ignore')

def match_image_mask_pairs(original_root, mask_root):
    """ì›ë³¸ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ íŒŒì¼ì„ ë§¤ì¹­"""
    print("="*60)
    print("ğŸ“Š ë°ì´í„° ë§¤ì¹­ ë° ìˆ˜ì§‘")
    print("="*60)
    print(f"ğŸ” ë°ì´í„° ë§¤ì¹­ ì‹œì‘")
    print(f"  ì›ë³¸ ì´ë¯¸ì§€: {original_root}")
    print(f"  ë§ˆìŠ¤í¬ ì´ë¯¸ì§€: {mask_root}")
    
    image_paths = []
    mask_paths = []
    
    original_root = Path(original_root)
    mask_root = Path(mask_root)
    
    # í´ë” ë§¤í•‘ í…Œì´ë¸”
    folder_mapping = {
        'Fr5_intertek_1st_250526': '1st',
        'Fr5_intertek_2nd_250526': '2nd', 
        'Fr5_intertek_3rd_250526': '3rd',
        'Fr5_intertek_4th_250526': '4th',
        'Fr5_intertek_5th_250526': '5th',
        'Fr5_intertek_6th_250526': '6th',
        'Fr5_intertek_7th_250526': '7th'
    }
    
    total_pairs = 0
    
    for original_folder, mask_folder in folder_mapping.items():
        original_folder_path = original_root / original_folder
        mask_folder_path = mask_root / mask_folder
        
        if not original_folder_path.exists():
            print(f"âš ï¸  ì›ë³¸ í´ë” ì—†ìŒ: {original_folder_path}")
            continue
            
        if not mask_folder_path.exists():
            print(f"âš ï¸  ë§ˆìŠ¤í¬ í´ë” ì—†ìŒ: {mask_folder_path}")
            continue
            
        print(f"ğŸ“ ì²˜ë¦¬ ì¤‘: {original_folder} â†’ {mask_folder}")
        
        # left, right, top ì‹œì ë³„ ì²˜ë¦¬
        for view in ['left', 'right', 'top']:
            original_view_path = original_folder_path / view
            mask_view_path = mask_folder_path / view / 'masks'
            
            if not original_view_path.exists():
                print(f"  âš ï¸  ì›ë³¸ {view} í´ë” ì—†ìŒ")
                continue
                
            if not mask_view_path.exists():
                print(f"  âš ï¸  ë§ˆìŠ¤í¬ {view}/masks í´ë” ì—†ìŒ: {mask_view_path}")
                continue
            
            view_pairs = 0
            unmatched_samples = []
            
            # ì›ë³¸ ì´ë¯¸ì§€ë“¤ ì°¾ê¸°
            for img_ext in ['*.jpg', '*.jpeg', '*.JPG', '*.JPEG']:
                for original_img_path in original_view_path.glob(img_ext):
                    # ë§ˆìŠ¤í¬ íŒŒì¼ëª… íŒ¨í„´ë“¤ ì‹œë„
                    possible_mask_names = [
                    ]
                    
                    found = False
                    for possible_name in possible_mask_names:
                        possible_mask_path = mask_view_path / possible_name
                        if possible_mask_path.exists():
                            image_paths.append(str(original_img_path))
                            mask_paths.append(str(possible_mask_path))
                            view_pairs += 1
                            found = True
                            break
                    
                    if not found:
                        unmatched_samples.append(original_img_path.name)
            
            if view_pairs > 0:
                print(f"  âœ… {view}: {view_pairs}ê°œ ë§¤ì¹­ ìŒ")
                total_pairs += view_pairs
                
                if unmatched_samples:
                    print(f"    âš ï¸  ë§¤ì¹­ ì‹¤íŒ¨ ({len(unmatched_samples)}ê°œ): {unmatched_samples[:3]}")
            else:
                print(f"  âŒ {view}: ë§¤ì¹­ ì‹¤íŒ¨")
    
    print(f"\nğŸ‰ ì´ {len(image_paths)}ê°œì˜ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
    return image_paths, mask_paths

class RobotArmDataset(Dataset):
    def __init__(self, image_paths, mask_paths, transform=None, is_train=True):
        self.image_paths = image_paths
        self.mask_paths = mask_paths
        self.transform = transform
        self.is_train = is_train
        
    def __len__(self):
        return len(self.image_paths)
    
    def __getitem__(self, idx):
        # ì›ë³¸ RGB ì´ë¯¸ì§€ ë¡œë“œ
        image_path = self.image_paths[idx]
        image = cv2.imread(image_path)
        
        if image is None:
            raise ValueError(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
            
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ë¡œë“œ
        mask_path = self.mask_paths[idx]
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        if mask is None:
            raise ValueError(f"ë§ˆìŠ¤í¬ ë¡œë“œ ì‹¤íŒ¨: {mask_path}")
        
        # ë§ˆìŠ¤í¬ë¥¼ ì´ì§„í™” (0: ë°°ê²½, 1: ë¡œë´‡íŒ”)
        mask = (mask > 127).astype(np.uint8)
        
        # ë³€í™˜ ì ìš©
        if self.transform:
            transformed = self.transform(image=image, mask=mask)
            image = transformed['image']
            mask = transformed['mask']
        
        return {
            'image': image,
            'mask': mask.long(),
            'image_path': image_path,
            'mask_path': mask_path
        }    

def get_train_transforms(image_size=512, augmentation_level='moderate'):
    """
    ë°ì´í„° ì¦ê°• ì„¤ì •
    augmentation_level: 'light', 'moderate', 'heavy'
    """
    
    if augmentation_level == 'light':
        # ê°€ë²¼ìš´ ì¦ê°• (ë¹ ë¥¸ í›ˆë ¨, ì•ˆì •ì )
        return A.Compose([
            A.Resize(image_size, image_size),
            A.HorizontalFlip(p=0.5),
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    elif augmentation_level == 'moderate':
        # ì¤‘ê°„ ì¦ê°• (ê· í˜•ì¡íŒ ì„±ëŠ¥, ê¶Œì¥)
        return A.Compose([
            A.Resize(image_size, image_size),
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.2),
            A.RandomRotate90(p=0.5),
            A.ShiftScaleRotate(
                shift_limit=0.1, 
                scale_limit=0.1, 
                rotate_limit=15, 
                p=0.5
            ),
            A.RandomBrightnessContrast(
                brightness_limit=0.2, 
                contrast_limit=0.2, 
                p=0.5
            ),
            A.HueSaturationValue(
                hue_shift_limit=10, 
                sat_shift_limit=20, 
                val_shift_limit=10, 
                p=0.3
            ),
            A.GaussNoise(var_limit=(10, 50), p=0.3),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    elif augmentation_level == 'heavy':
        # ê°•í•œ ì¦ê°• (ë¡œë´‡íŒ” íŠ¹í™”, ë” robustí•œ ëª¨ë¸)
        return A.Compose([
            A.Resize(image_size, image_size),
            
            # ê¸°í•˜í•™ì  ë³€í™˜ (ë¡œë´‡íŒ”ì˜ ë‹¤ì–‘í•œ ìì„¸)
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.3),
            A.RandomRotate90(p=0.5),
            A.Rotate(limit=30, p=0.5),  # ë” í° íšŒì „ê°
            A.ShiftScaleRotate(
                shift_limit=0.15, 
                scale_limit=0.15, 
                rotate_limit=20, 
                p=0.6
            ),
            
            # ìƒ‰ìƒ/ì¡°ëª… ë³€í™˜ (ë‹¤ì–‘í•œ í™˜ê²½ ì¡°ê±´)
            A.RandomBrightnessContrast(
                brightness_limit=0.3, 
                contrast_limit=0.3, 
                p=0.6
            ),
            A.HueSaturationValue(
                hue_shift_limit=15, 
                sat_shift_limit=30, 
                val_shift_limit=15, 
                p=0.4
            ),
            A.RandomGamma(gamma_limit=(80, 120), p=0.3),
            A.CLAHE(clip_limit=2.0, p=0.3),  # ëŒ€ë¹„ ê°œì„ 
            
            # ë…¸ì´ì¦ˆ ë° ë¸”ëŸ¬ (ì¹´ë©”ë¼ í’ˆì§ˆ ì‹œë®¬ë ˆì´ì…˜)
            A.GaussNoise(var_limit=(10, 80), p=0.4),
            A.GaussianBlur(blur_limit=3, p=0.2),
            A.MotionBlur(blur_limit=3, p=0.2),
            
            # ê°€ë ¤ì§ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ í™˜ê²½ì˜ ì¥ì• ë¬¼)
            A.CoarseDropout(
                max_holes=3, 
                max_height=32, 
                max_width=32, 
                min_holes=1, 
                min_height=8, 
                min_width=8, 
                p=0.3
            ),
            
            # ê·¸ë¦¼ì íš¨ê³¼ (ì¡°ëª… ë³€í™”) - ì¼ë¶€ ë²„ì „ì—ì„œ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
            # A.RandomShadow(
            #     shadow_roi=(0, 0.5, 1, 1),
            #     num_shadows_lower=1,
            #     num_shadows_upper=2,
            #     shadow_dimension=5,
            #     p=0.3
            # ),
            
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2()
        ])
    
    else:
        raise ValueError("augmentation_level must be 'light', 'moderate', or 'heavy'")

def get_val_transforms(image_size=512):
    return A.Compose([
        A.Resize(image_size, image_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def debug_tensor_shapes(images, masks, outputs, step_name=""):
    """í…ì„œ í¬ê¸° ë””ë²„ê¹…ìš© í•¨ìˆ˜"""
    print(f"\nğŸ” {step_name} í…ì„œ í¬ê¸°:")
    print(f"  ì…ë ¥ ì´ë¯¸ì§€: {images.shape}")
    print(f"  íƒ€ê²Ÿ ë§ˆìŠ¤í¬: {masks.shape}")
    print(f"  ëª¨ë¸ ì¶œë ¥: {outputs.shape}")
    
    if images.shape[-2:] != outputs.shape[-2:]:
        print(f"  âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ ê°ì§€!")
        print(f"    ì…ë ¥ í¬ê¸°: {images.shape[-2:]}")
        print(f"    ì¶œë ¥ í¬ê¸°: {outputs.shape[-2:]}")
    else:
        print(f"  âœ… í¬ê¸° ì¼ì¹˜ í™•ì¸")
    """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
    print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ (ìƒ˜í”Œ {num_samples}ê°œ)")
    print("="*50)
    
    for i in range(min(num_samples, len(image_paths))):
        img_path = image_paths[i]
        mask_path = mask_paths[i]
        
        print(f"\nğŸ“‹ ìƒ˜í”Œ {i+1}:")
        print(f"  ì›ë³¸: {Path(img_path).name}")
        print(f"  ë§ˆìŠ¤í¬: {Path(mask_path).name}")
        
        try:
            img = cv2.imread(img_path)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            
            if img is None:
                print(f"  âŒ ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
                continue
                
            if mask is None:
                print(f"  âŒ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
                continue
            
            print(f"  ğŸ“ ì›ë³¸ í¬ê¸°: {img.shape}")
            print(f"  ğŸ“ ë§ˆìŠ¤í¬ í¬ê¸°: {mask.shape}")
            
            unique_values = np.unique(mask)
            print(f"  ğŸ¨ ë§ˆìŠ¤í¬ í”½ì…€ê°’: {unique_values}")
            
            robot_pixels = np.sum(mask > 127)
            total_pixels = mask.shape[0] * mask.shape[1]
            robot_ratio = robot_pixels / total_pixels * 100
            print(f"  ğŸ¤– ë¡œë´‡íŒ” ë¹„ìœ¨: {robot_ratio:.1f}%")
            
            print(f"  âœ… ì •ìƒ")
            
        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
